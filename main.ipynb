{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonochof/LLMAgents/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa8bLyZQEbwA"
      },
      "source": [
        "# Spontaneous Emergence of Agent Individuality Through Social Interactions in Large Language Model-Based Communities\n",
        "Ryosuke Takata, Atsushi Masumori, Takashi Ikegami: Spontaneous Emergence of Agent Individuality Through Social Interactions in Large Language Model-Based Communities, Entropy, 26(12), 1092 (2024).\n",
        "\n",
        "https://www.mdpi.com/3086740"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0cUNA7AFAmB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentencepiece accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ckng6TiFCNt"
      },
      "outputs": [],
      "source": [
        "# huggingface access token required here\n",
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaNW0q_W7t0t"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT6znfrjEfAc"
      },
      "outputs": [],
      "source": [
        "FIELD_SIZE = 50\n",
        "HEAR_DISTANCE = 5\n",
        "AGENT_NUM = 10\n",
        "MAX_STEP = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MsdqervFH0E"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHHraWpjEfR6"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "\n",
        "    def __init__(self, name, position):\n",
        "        self.name = name\n",
        "        self.position = position\n",
        "        self.last_tweet = \"\"\n",
        "        self.last_movement = \"\"\n",
        "        self.last_memory = \"\"\n",
        "        self.pending_messages = []\n",
        "        self.receive_messages = []\n",
        "\n",
        "    def run_llm(self, prompt):\n",
        "        with torch.no_grad():\n",
        "            token_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "            output_ids = model.generate(\n",
        "                token_ids.to(model.device),\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                top_p=0.95,\n",
        "                top_k=40,\n",
        "                max_new_tokens=256,\n",
        "            )\n",
        "        output = tokenizer.decode(output_ids[0][token_ids.size(1) :])\n",
        "        return output\n",
        "\n",
        "    def pend_message(self, message):\n",
        "        m = message if not re.search(r'\"(.*)\"', message) else re.search(r'\"(.*)\"', message).group(1)\n",
        "        self.pending_messages.append(m)\n",
        "\n",
        "    def receive_message(self):\n",
        "        self.receive_messages = self.pending_messages\n",
        "        self.pending_messages = []\n",
        "\n",
        "    def generate_inst(self):\n",
        "        return \"[INST] You are {} at position {}. The field size is {} by {} with periodic boundary conditions, and there are a total of {} agents. You are free to move around the field and converse with other agents. You have a summary memory of the situation so far: {}. \".format(self.name, str(self.position), FIELD_SIZE, FIELD_SIZE, AGENT_NUM, (\"No memory\" if self.last_memory == \"\" else self.last_memory))\n",
        "\n",
        "    def generate_message(self):\n",
        "        prompt = self.generate_inst() + \"You received messages from the surrounding agents: {}. Based on the above, you send a message to the surrounding agents. Your message will reach agents up to distance {} away. What message do you send? [/INST]\".format((\"No messages\" if self.receive_messages == [] else self.receive_messages), HEAR_DISTANCE)\n",
        "        output = self.run_llm(prompt)\n",
        "        self.last_tweet = output\n",
        "        print(\"[{} message prompt] {}\".format(self.name, prompt))\n",
        "        print(\"[{} message output] {}\".format(self.name, output))\n",
        "        return output\n",
        "\n",
        "    def generate_movement(self):\n",
        "        prompt = self.generate_inst() + 'Based on the above, what the next your move command? Choose only one of the following: [\"x+1\", \"x-1\", \"y+1\", \"y-1\", \"stay\"] [/INST]'\n",
        "        output = self.run_llm(prompt)\n",
        "        self.last_movement = output\n",
        "        move = \"stay\" if not re.search(r'\"(x\\+1|x-1|y\\+1|y-1|stay)\"', output) else re.search(r'\"(x\\+1|x-1|y\\+1|y-1|stay)\"', output).group(1)\n",
        "        print(\"[{} move prompt] {}\".format(self.name, prompt))\n",
        "        print(\"[{} move output] {}\".format(self.name, output))\n",
        "        print(\"[{} move command] {}\".format(self.name, move))\n",
        "        return move\n",
        "\n",
        "    def generate_memory(self):\n",
        "        prompt = self.generate_inst() + \"You received messages from the surrounding agents: {}. Based on the above, summarize the situation you and the other agents have been in so far for you to remember. [/INST]\".format(\"No messages\" if self.receive_messages == [] else self.receive_messages)\n",
        "        output = self.run_llm(prompt)\n",
        "        self.last_memory = output\n",
        "        print(\"[{} memory prompt] {}\".format(self.name, prompt))\n",
        "        print(\"[{} memory output] {}\".format(self.name, output))\n",
        "        return output\n",
        "\n",
        "    def memorize(self):\n",
        "        self.last_memory = self.generate_memory()\n",
        "\n",
        "    def move(self, direction):\n",
        "        if direction == \"y+1\":\n",
        "            self.position = (self.position[0], self.position[1] + 1)\n",
        "        elif direction == \"y-1\":\n",
        "            self.position = (self.position[0], self.position[1] - 1)\n",
        "        elif direction == \"x-1\":\n",
        "            self.position = (self.position[0] - 1, self.position[1])\n",
        "        elif direction == \"x+1\":\n",
        "            self.position = (self.position[0] + 1, self.position[1])\n",
        "        elif direction == \"stay\":\n",
        "            self.position = (self.position[0], self.position[1])\n",
        "        else:\n",
        "            self.position = (self.position[0], self.position[1])\n",
        "        self.position = (self.position[0] % FIELD_SIZE, self.position[1] % FIELD_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_XwhNeKFNK-"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    def __init__(self, agents_num):\n",
        "        self.agents = [Agent(name=f\"agent{i}\", position=(random.randint(0, FIELD_SIZE-1), random.randint(0, FIELD_SIZE-1))) for i in range(agents_num)]\n",
        "        self.log_positions = []\n",
        "        self.log_tweets = []\n",
        "        self.log_movements = []\n",
        "        self.log_memories = []\n",
        "\n",
        "    def reset(self):\n",
        "        for agent in self.agents:\n",
        "            agent.position = (random.randint(0, FIELD_SIZE-1), random.randint(0, FIELD_SIZE-1))\n",
        "\n",
        "    def is_hearable_distance(self, a, b):\n",
        "        return (abs(a[0] - b[0]) <= HEAR_DISTANCE or abs(a[0] - b[0]) >= FIELD_SIZE - HEAR_DISTANCE) and (abs(a[1] - b[1]) <= HEAR_DISTANCE or abs(a[1] - b[1]) >= FIELD_SIZE - HEAR_DISTANCE)\n",
        "\n",
        "    def send_message(self, agent, message):\n",
        "        for a in self.agents:\n",
        "            if a != agent and self.is_hearable_distance(a.position, agent.position):\n",
        "                a.pend_message(message)\n",
        "\n",
        "    def step(self):\n",
        "        for agent in self.agents:\n",
        "            print(agent.name)\n",
        "            self.send_message(agent, agent.generate_message())\n",
        "\n",
        "        for agent in self.agents:\n",
        "            agent.receive_message()\n",
        "\n",
        "        for agent in self.agents:\n",
        "            agent.memorize()\n",
        "\n",
        "        for agent in self.agents:\n",
        "            agent.move(agent.generate_movement())\n",
        "\n",
        "    def run(self, num_steps):\n",
        "        self.log_positions.append([agent.position for agent in self.agents])\n",
        "        self.log_tweets.append([agent.last_tweet for agent in self.agents])\n",
        "        self.log_movements.append([agent.last_movement for agent in self.agents])\n",
        "        self.log_memories.append([agent.last_memory for agent in self.agents])\n",
        "        for i in range(num_steps):\n",
        "            print(\"\\n\\n=== step {} ===\".format(i))\n",
        "            self.step()\n",
        "            self.log_positions.append([agent.position for agent in self.agents])\n",
        "            self.log_tweets.append([agent.last_tweet for agent in self.agents])\n",
        "            self.log_movements.append([agent.last_movement for agent in self.agents])\n",
        "            self.log_memories.append([agent.last_memory for agent in self.agents])\n",
        "\n",
        "    def print_positions(self):\n",
        "        for agent in self.agents:\n",
        "            print(f\"{agent.name} is at {agent.position}\")\n",
        "\n",
        "    def print_messages(self):\n",
        "        for agent in self.agents:\n",
        "            print(f\"{agent.name} received {agent.messages}\")\n",
        "\n",
        "    def print_field(self):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.scatter([agent.position[0] for agent in self.agents], [agent.position[1] for agent in self.agents])\n",
        "        plt.xlim(0, FIELD_SIZE)\n",
        "        plt.ylim(0, FIELD_SIZE)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr1KPObL5ZlT"
      },
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "env = Environment(agents_num=AGENT_NUM)\n",
        "env.print_positions()\n",
        "\n",
        "env.run(MAX_STEP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UVsnP472DaX"
      },
      "outputs": [],
      "source": [
        "# dump\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('log_positions_{}.pkl'.format(AGENT_NUM), 'wb') as f:\n",
        "    pickle.dump(env.log_positions, f)\n",
        "\n",
        "with open('log_tweets_{}.pkl'.format(AGENT_NUM), 'wb') as f:\n",
        "    pickle.dump(env.log_tweets, f)\n",
        "\n",
        "with open('log_movements_{}.pkl'.format(AGENT_NUM), 'wb') as f:\n",
        "    pickle.dump(env.log_movements, f)\n",
        "\n",
        "with open('log_memories_{}.pkl'.format(AGENT_NUM), 'wb') as f:\n",
        "    pickle.dump(env.log_memories, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}